{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HDXER_PATH\"] = \"/home/alexi/Documents/HDXer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ValDXer testing\n",
    "import os\n",
    "from ValDX.ValidationDX import ValDXer\n",
    "from ValDX.VDX_Settings import Settings\n",
    "import pandas as pd\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.coordinates.XTC import XTCWriter\n",
    "\n",
    "from pdbfixer import PDBFixer\n",
    "from openmm.app import PDBFile\n",
    "\n",
    "settings = Settings()\n",
    "settings.replicates = 3\n",
    "settings.gamma_range = (2,6)\n",
    "settings.train_frac = 0.5\n",
    "settings.RW_exponent = [0]\n",
    "settings.stride = 1000\n",
    "\n",
    "\n",
    "settings.RW_do_reweighting = True\n",
    "settings.RW_do_params = False\n",
    "import pickle\n",
    "\n",
    "\n",
    "raw_run_outputs = {}\n",
    "analysis_dumps = {}\n",
    "analysis_df = pd.DataFrame()\n",
    "names = []\n",
    "save_paths = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_main_BPTI():\n",
    "    # BPTI data\n",
    "    expt_name = 'Experimental'\n",
    "    test_name = \"RW_BPTI_tutMD\"\n",
    "\n",
    "    BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/HDXer_tutorial/BPTI\"\n",
    "    \n",
    "    # BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/HDXer_tutorial/BPTI\"\n",
    "    expt_dir = os.path.join(BPTI_dir, \"BPTI_expt_data\")\n",
    "    print(expt_dir)\n",
    "    os.listdir(expt_dir)\n",
    "\n",
    "    segs_name = \"BPTI_residue_segs.txt\"\n",
    "    segs_path = os.path.join(expt_dir, segs_name)\n",
    "\n",
    "    hdx_name = \"BPTI_expt_dfracs.dat\"\n",
    "    hdx_path = os.path.join(expt_dir, hdx_name)\n",
    "    print(hdx_path)\n",
    "\n",
    "    rates_name = \"BPTI_Intrinsic_rates.dat\"\n",
    "    rates_path = os.path.join(expt_dir, rates_name)\n",
    "    sim_name = 'BPTI_MD'\n",
    "\n",
    "    sim_dir = os.path.join(BPTI_dir, \"BPTI_simulations\")\n",
    "\n",
    "    os.listdir(sim_dir)\n",
    "\n",
    "    md_reps = 1\n",
    "    rep_dirs = [\"Run_\"+str(i+1) for i in range(md_reps)]\n",
    "\n",
    "    top_name = \"bpti_5pti_eq6_protonly.gro\"\n",
    "\n",
    "    top_path = os.path.join(sim_dir, rep_dirs[0], top_name)\n",
    "\n",
    "    traj_name = \"bpti_5pti_reimg_protonly.xtc\"\n",
    "\n",
    "    traj_paths = [os.path.join(sim_dir, rep_dir, traj_name) for rep_dir in rep_dirs]\n",
    "\n",
    "    print(top_path)\n",
    "    print(traj_paths)\n",
    "\n",
    "\n",
    "    small_traj_name = traj_name.replace(\".xtc\",\"_small.xtc\")\n",
    "    small_traj_path = os.path.join(sim_dir, small_traj_name)\n",
    "\n",
    "    u = mda.Universe(top_path, traj_paths)\n",
    "\n",
    "    \n",
    "        \n",
    "    with XTCWriter(small_traj_path, n_atoms=u.atoms.n_atoms) as W:\n",
    "        for ts in u.trajectory[:5]:\n",
    "                W.write(u.atoms)\n",
    "\n",
    "    traj_paths = [small_traj_path]\n",
    "    \n",
    "\n",
    "    return hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name = pre_process_main_BPTI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split_test_BPTI(split_mode, name, system):\n",
    "\n",
    "    # settings.split_mode = 'R'\n",
    "    settings.split_mode = split_mode\n",
    "    settings.name = \"_\".join([name, split_mode, system])\n",
    "\n",
    "    VDX = ValDXer(settings)\n",
    "\n",
    "    VDX.load_HDX_data(HDX_path=hdx_path, SEG_path=segs_path, calc_name=expt_name)\n",
    "    # VDX.load_intrinsic_rates(path=rates_path, calc_name=expt_name)\n",
    "\n",
    "    VDX.load_structures(top_path=top_path, traj_paths=traj_paths, calc_name=test_name)\n",
    "\n",
    "    run_outputs = VDX.run_VDX(calc_name=test_name, expt_name=expt_name)\n",
    "    analysis_dump, df, name = VDX.dump_analysis()\n",
    "    save_path = VDX.save_experiment()\n",
    "\n",
    "    return run_outputs, analysis_dump, df, name, save_path\n",
    "\n",
    "\n",
    "splits = ['r', 's', 'R3',  'Sp', 'SR']\n",
    "split_names = ['naiverandom', 'NC_Termini', 'RedundantK',  'pINspace', 'spaceK']\n",
    "system = test_name\n",
    "\n",
    "# raw_run_outputs = {}\n",
    "# analysis_dumps = {}\n",
    "# analysis_df = pd.DataFrame()\n",
    "# names = []\n",
    "# save_paths = []\n",
    "\n",
    "\n",
    "for split, split_name in zip(splits, split_names):\n",
    "    run_outputs, analysis_dump, df, name, save_path = run_split_test_BPTI(split, split_name, system)\n",
    "    raw_run_outputs[name] = run_outputs\n",
    "    analysis_dumps.update(analysis_dump)\n",
    "    analysis_df = pd.concat([analysis_df, df])\n",
    "    names.append(name)\n",
    "    save_paths.append(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_main_MBP():\n",
    "    # BPTI data\n",
    "    expt_name = 'Experimental'\n",
    "    test_name = \"RW_MBPwt1_apo_AF\"\n",
    "    BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/MBP/MaltoseBindingProtein\"\n",
    "\n",
    "    # BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/HDXer_tutorial/BPTI\"\n",
    "\n",
    "    sim_name = 'MBPwt_AF'\n",
    "    os.listdir(BPTI_dir)\n",
    "\n",
    "    segs_name = \"MBP_wt1_segs.txt\"\n",
    "    segs_path = os.path.join(BPTI_dir, segs_name)\n",
    "\n",
    "    hdx_name = \"MBP_wt1.dat\"\n",
    "    hdx_path = os.path.join(BPTI_dir, hdx_name)\n",
    "    print(hdx_path)\n",
    "\n",
    "    rates_name = \"out__train_MD_Simulated_1Intrinsic_rates.dat\"\n",
    "    rates_path = os.path.join(BPTI_dir, rates_name)\n",
    "\n",
    "    sim_dir = os.path.join(BPTI_dir, \"alphafold_quick\")\n",
    "\n",
    "    pdb_list = [f for f in os.listdir(sim_dir) if f.endswith('.pdb')]\n",
    "\n",
    "    print(pdb_list) \n",
    "\n",
    "\n",
    "    H_sim_dir = os.path.join(BPTI_dir, \"alphafold_H\")\n",
    "\n",
    "    os.makedirs(H_sim_dir, exist_ok=True)\n",
    "\n",
    "    for pdb in pdb_list:\n",
    "        fixer = PDBFixer(os.path.join(sim_dir, pdb))\n",
    "        fixer.addMissingHydrogens(7.0)\n",
    "        H_pdb_name = pdb.replace('.pdb', '_H.pdb')\n",
    "        PDBFile.writeFile(fixer.topology, fixer.positions, open(os.path.join(H_sim_dir, H_pdb_name), 'w'), keepIds=True)\n",
    "\n",
    "    pdb_list = [f for f in os.listdir(H_sim_dir) if f.endswith('.pdb')]\n",
    "\n",
    "\n",
    "    top_path = os.path.join(H_sim_dir, pdb_list[0])\n",
    "    pdb_paths = [os.path.join(H_sim_dir, i) for i in pdb_list]\n",
    "\n",
    "    print(top_path)\n",
    "    print(pdb_paths)\n",
    "\n",
    "\n",
    "    small_traj_name = top_path.replace(\".pdb\",\"_small.xtc\")\n",
    "    small_traj_path = os.path.join(sim_dir, small_traj_name)\n",
    "\n",
    "    u = mda.Universe(top_path, pdb_paths)\n",
    "\n",
    "\n",
    "        \n",
    "    with XTCWriter(small_traj_path, n_atoms=u.atoms.n_atoms) as W:\n",
    "        for ts in u.trajectory:\n",
    "                W.write(u.atoms)\n",
    "\n",
    "    # traj_paths = [os.path.join(sim_dir, i) for i in os.listdir(sim_dir) if i.endswith(\".pdb\")]\n",
    "    \n",
    "    traj_paths = [small_traj_path]\n",
    "\n",
    "    print(traj_paths)\n",
    "    return hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name\n",
    "\n",
    "hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name = pre_process_main_MBP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split_test_MBP(split_mode, name, system):\n",
    "\n",
    "    # settings.split_mode = 'R'\n",
    "    settings.split_mode = split_mode\n",
    "    settings.name = \"_\".join([name, split_mode, system])\n",
    "    settings.times = [30, 240, 1800, 14400]\n",
    "\n",
    "    VDX = ValDXer(settings)\n",
    "\n",
    "    VDX.load_HDX_data(HDX_path=hdx_path, SEG_path=segs_path, calc_name=expt_name)\n",
    "    # VDX.load_intrinsic_rates(path=rates_path, calc_name=expt_name)\n",
    "\n",
    "    VDX.load_structures(top_path=top_path, traj_paths=traj_paths, calc_name=test_name)\n",
    "\n",
    "    run_outputs = VDX.run_VDX(calc_name=test_name, expt_name=expt_name)\n",
    "    analysis_dump, df, name = VDX.dump_analysis()\n",
    "    save_path = VDX.save_experiment()\n",
    "\n",
    "    return run_outputs, analysis_dump, df, name, save_path\n",
    "\n",
    "\n",
    "splits = ['r', 's', 'R3',  'Sp', 'SR']\n",
    "split_names = ['naiverandom', 'NC_Termini', 'RedundantK',  'pINspace', 'spaceK']\n",
    "system = test_name\n",
    "\n",
    "# raw_run_outputs = {}\n",
    "# analysis_dumps = {}\n",
    "# analysis_df = pd.DataFrame()\n",
    "# names = []\n",
    "# save_paths = []\n",
    "\n",
    "\n",
    "for split, split_name in zip(splits, split_names):\n",
    "    run_outputs, analysis_dump, df, name, save_path = run_split_test_MBP(split, split_name, system)\n",
    "    raw_run_outputs[name] = run_outputs\n",
    "    analysis_dumps.update(analysis_dump)\n",
    "    analysis_df = pd.concat([analysis_df, df])\n",
    "    names.append(name)\n",
    "    save_paths.append(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_main_BRD4():\n",
    "    # BPTI data\n",
    "    BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/BRD4/BRD4_APO\"\n",
    "\n",
    "    # BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/HDXer_tutorial/BPTI\"\n",
    "    expt_name = 'Experimental'\n",
    "    test_name = \"RW_BRD4apo_AF\"\n",
    "\n",
    "    os.listdir(BPTI_dir)\n",
    "\n",
    "    segs_name = \"BRD4_APO_segs.txt\"\n",
    "    segs_path = os.path.join(BPTI_dir, segs_name)\n",
    "\n",
    "    hdx_name = \"BRD4_APO.dat\"\n",
    "    hdx_path = os.path.join(BPTI_dir, hdx_name)\n",
    "    print(hdx_path)\n",
    "\n",
    "    rates_name = \"out__train_MD_Simulated_1Intrinsic_rates.dat\"\n",
    "    rates_path = os.path.join(BPTI_dir, rates_name)\n",
    "    sim_name = 'BRD4_AF'\n",
    "\n",
    "    sim_dir = os.path.join(BPTI_dir, \"alphafold_quick\")\n",
    "\n",
    "    pdb_list = [f for f in os.listdir(sim_dir) if f.endswith('.pdb')]\n",
    "\n",
    "    print(pdb_list) \n",
    "\n",
    "\n",
    "    H_sim_dir = os.path.join(BPTI_dir, \"alphafold_H\")\n",
    "\n",
    "    os.makedirs(H_sim_dir, exist_ok=True)\n",
    "\n",
    "    for pdb in pdb_list:\n",
    "        fixer = PDBFixer(os.path.join(sim_dir, pdb))\n",
    "        fixer.addMissingHydrogens(7.0)\n",
    "        H_pdb_name = pdb.replace('.pdb', '_H.pdb')\n",
    "        PDBFile.writeFile(fixer.topology, fixer.positions, open(os.path.join(H_sim_dir, H_pdb_name), 'w'), keepIds=True)\n",
    "\n",
    "    pdb_list = [f for f in os.listdir(H_sim_dir) if f.endswith('.pdb')]\n",
    "\n",
    "\n",
    "    top_path = os.path.join(H_sim_dir, pdb_list[0])\n",
    "    pdb_paths = [os.path.join(H_sim_dir, i) for i in pdb_list]\n",
    "\n",
    "    print(top_path)\n",
    "    print(pdb_paths)\n",
    "\n",
    "\n",
    "    small_traj_name = top_path.replace(\".pdb\",\"_small.xtc\")\n",
    "    small_traj_path = os.path.join(sim_dir, small_traj_name)\n",
    "\n",
    "    u = mda.Universe(top_path, pdb_paths)\n",
    "\n",
    "\n",
    "        \n",
    "    with XTCWriter(small_traj_path, n_atoms=u.atoms.n_atoms) as W:\n",
    "        for ts in u.trajectory:\n",
    "                W.write(u.atoms)\n",
    "\n",
    "    # traj_paths = [os.path.join(sim_dir, i) for i in os.listdir(sim_dir) if i.endswith(\".pdb\")]\n",
    "    \n",
    "    traj_paths = [small_traj_path]\n",
    "\n",
    "    print(traj_paths)\n",
    "    return hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name\n",
    "hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name = pre_process_main_BRD4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split_test_BRD4(split_mode, name, system):\n",
    "\n",
    "    # settings.split_mode = 'R'\n",
    "    settings.split_mode = split_mode\n",
    "    settings.name = \"_\".join([name, split_mode, system])\n",
    "    settings.times = [0.0, 15.0, 60.0, 600.0, 3600.0, 14400.0]\n",
    "    settings.replicates = 1\n",
    "\n",
    "    VDX = ValDXer(settings)\n",
    "\n",
    "    VDX.load_HDX_data(HDX_path=hdx_path, SEG_path=segs_path, calc_name=expt_name)\n",
    "    # VDX.load_intrinsic_rates(path=rates_path, calc_name=expt_name)\n",
    "\n",
    "    VDX.load_structures(top_path=top_path, traj_paths=traj_paths, calc_name=test_name)\n",
    "    try:\n",
    "        run_outputs = VDX.run_VDX(calc_name=test_name, expt_name=expt_name)\n",
    "        try:\n",
    "            analysis_dump, df, name = VDX.dump_analysis()\n",
    "            save_path = VDX.save_experiment()\n",
    "        except:\n",
    "            analysis_dump = {}\n",
    "            df = pd.DataFrame()\n",
    "            name = settings.name\n",
    "            save_path = \"error\"\n",
    "    except:\n",
    "        run_outputs = {}\n",
    "        analysis_dump = {}\n",
    "        df = pd.DataFrame()\n",
    "        name = settings.name\n",
    "        save_path = \"error\"\n",
    "        \n",
    "\n",
    "    return run_outputs, analysis_dump, df, name, save_path\n",
    "\n",
    "\n",
    "splits = ['r', 's', 'R3',  'Sp', 'SR']\n",
    "split_names = ['naiverandom', 'NC_Termini', 'RedundantK',  'pINspace', 'spaceK']\n",
    "system = test_name\n",
    "\n",
    "# raw_run_outputs = {}\n",
    "# analysis_dumps = {}\n",
    "# analysis_df = pd.DataFrame()\n",
    "# names = []\n",
    "# save_paths = []\n",
    "\n",
    "\n",
    "for split, split_name in zip(splits, split_names):\n",
    "    run_outputs, analysis_dump, df, name, save_path = run_split_test_BRD4(split, split_name, system)\n",
    "    raw_run_outputs[name] = run_outputs\n",
    "    analysis_dumps.update(analysis_dump)\n",
    "    analysis_df = pd.concat([analysis_df, df])\n",
    "    names.append(name)\n",
    "    save_paths.append(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_main_HOIP():\n",
    "    # BPTI data\n",
    "    expt_name = 'Experimental'\n",
    "    test_name = \"RW_HOIPapo_AF\"\n",
    "    BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/HOIP/HOIP_apo/\"\n",
    "\n",
    "    # BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/HDXer_tutorial/BPTI\"\n",
    "\n",
    "    sim_name = 'HOIP_apo_AF'\n",
    "    os.listdir(BPTI_dir)\n",
    "\n",
    "    segs_name = \"HOIP_APO_segs.txt\"\n",
    "    segs_path = os.path.join(BPTI_dir, segs_name)\n",
    "\n",
    "    hdx_name = \"HOIP_apo.dat\"\n",
    "    hdx_path = os.path.join(BPTI_dir, hdx_name)\n",
    "    print(hdx_path)\n",
    "\n",
    "    rates_name = \"out__train_MD_Simulated_1Intrinsic_rates.dat\"\n",
    "    rates_path = os.path.join(BPTI_dir, rates_name)\n",
    "\n",
    "    sim_dir = os.path.join(BPTI_dir, \"alphafold_quick\")\n",
    "\n",
    "    pdb_list = [f for f in os.listdir(sim_dir) if f.endswith('.pdb')]\n",
    "\n",
    "    print(pdb_list) \n",
    "\n",
    "\n",
    "    H_sim_dir = os.path.join(BPTI_dir, \"alphafold_H\")\n",
    "\n",
    "    os.makedirs(H_sim_dir, exist_ok=True)\n",
    "\n",
    "    for pdb in pdb_list:\n",
    "        continue\n",
    "        fixer = PDBFixer(os.path.join(H_sim_dir, pdb))\n",
    "        fixer.addMissingHydrogens(7.0)\n",
    "        H_pdb_name = pdb.replace('.pdb', '_H.pdb')\n",
    "        PDBFile.writeFile(fixer.topology, fixer.positions, open(os.path.join(H_sim_dir, H_pdb_name), 'w'), keepIds=True)\n",
    "        break\n",
    "    pdb_list = [f for f in os.listdir(H_sim_dir) if f.endswith('.pdb')]\n",
    "\n",
    "\n",
    "    top_path = os.path.join(H_sim_dir, pdb_list[0])\n",
    "    pdb_paths = [os.path.join(H_sim_dir, i) for i in pdb_list]\n",
    "\n",
    "    print(top_path)\n",
    "    print(pdb_paths)\n",
    "\n",
    "\n",
    "    small_traj_name = top_path.replace(\".pdb\",\"_small.xtc\")\n",
    "    small_traj_path = os.path.join(sim_dir, small_traj_name)\n",
    "\n",
    "    u = mda.Universe(top_path, pdb_paths)\n",
    "        \n",
    "    with XTCWriter(small_traj_path, n_atoms=u.atoms.n_atoms) as W:\n",
    "        for ts in u.trajectory:\n",
    "            W.write(u.atoms)\n",
    "            # W.write(u.atoms)\n",
    "            # break\n",
    "    # traj_paths = [os.path.join(sim_dir, i) for i in os.listdir(sim_dir) if i.endswith(\".pdb\")]\n",
    "    \n",
    "    traj_paths = [small_traj_path]\n",
    "\n",
    "    print(traj_paths)\n",
    "    return hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name\n",
    "hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name = pre_process_main_HOIP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split_test_HOIP(split_mode, name, system):\n",
    "\n",
    "    # settings.split_mode = 'R'\n",
    "    settings.split_mode = split_mode\n",
    "    settings.name = \"_\".join([name, split_mode, system])\n",
    "    settings.times = [0.0, 0.5, 5.0]\n",
    "    settings.replicates = 1\n",
    "    VDX = ValDXer(settings)\n",
    "\n",
    "    VDX.load_HDX_data(HDX_path=hdx_path, SEG_path=segs_path, calc_name=expt_name)\n",
    "    # VDX.load_intrinsic_rates(path=rates_path, calc_name=expt_name)\n",
    "\n",
    "    VDX.load_structures(top_path=top_path, traj_paths=traj_paths, calc_name=test_name)\n",
    "\n",
    "    VDX.load_HDX_data(HDX_path=hdx_path, SEG_path=segs_path, calc_name=expt_name)\n",
    "    # VDX.load_intrinsic_rates(path=rates_path, calc_name=expt_name)\n",
    "\n",
    "    VDX.load_structures(top_path=top_path, traj_paths=traj_paths, calc_name=test_name)\n",
    "    try:\n",
    "        run_outputs = VDX.run_VDX(calc_name=test_name, expt_name=expt_name)\n",
    "        try:\n",
    "            analysis_dump, df, name = VDX.dump_analysis()\n",
    "            save_path = VDX.save_experiment()\n",
    "        except:\n",
    "            analysis_dump = {}\n",
    "            df = pd.DataFrame()\n",
    "            name = settings.name\n",
    "            save_path = \"error\"\n",
    "    except:\n",
    "        run_outputs = {}\n",
    "        analysis_dump = {}\n",
    "        df = pd.DataFrame()\n",
    "        name = settings.name\n",
    "        save_path = \"error\"\n",
    "        \n",
    "\n",
    "    return run_outputs, analysis_dump, df, name, save_path\n",
    "\n",
    "\n",
    "\n",
    "splits = ['r', 's', 'R3',  'Sp', 'SR']\n",
    "split_names = ['naiverandom', 'NC_Termini', 'RedundantK',  'pINspace', 'spaceK']\n",
    "system = test_name\n",
    "\n",
    "# raw_run_outputs = {}\n",
    "# analysis_dumps = {}\n",
    "# analysis_df = pd.DataFrame()\n",
    "# names = []\n",
    "# save_paths = []\n",
    "\n",
    "\n",
    "for split, split_name in zip(splits, split_names):\n",
    "    # continue\n",
    "    run_outputs, analysis_dump, df, name, save_path = run_split_test_HOIP(split, split_name, system)\n",
    "    raw_run_outputs[name] = run_outputs\n",
    "    analysis_dumps.update(analysis_dump)\n",
    "    analysis_df = pd.concat([analysis_df, df])\n",
    "    names.append(name)\n",
    "    save_paths.append(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_main_LXRa():\n",
    "    # BPTI data\n",
    "    BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/LXRalpha/LXRalpha_APO\"\n",
    "\n",
    "    # BPTI_dir = \"/home/alexi/Documents/ValDX/raw_data/HDXer_tutorial/BPTI\"\n",
    "    expt_name = 'Experimental'\n",
    "    test_name = \"RW_LXRa_apo_AF\"\n",
    "    os.listdir(BPTI_dir)\n",
    "\n",
    "    segs_name = \"LXRa_APO_segs.txt\"\n",
    "    segs_path = os.path.join(BPTI_dir, segs_name)\n",
    "\n",
    "    hdx_name = \"LXRa_APO.dat\"\n",
    "    hdx_path = os.path.join(BPTI_dir, hdx_name)\n",
    "    print(hdx_path)\n",
    "\n",
    "    rates_name = \"out__train_MD_Simulated_1Intrinsic_rates.dat\"\n",
    "    rates_path = os.path.join(BPTI_dir, rates_name)\n",
    "    sim_name = 'LXRa_AF'\n",
    "\n",
    "    sim_dir = os.path.join(BPTI_dir, \"alphafold_quick\")\n",
    "\n",
    "    pdb_list = [f for f in os.listdir(sim_dir) if f.endswith('.pdb')]\n",
    "\n",
    "    print(pdb_list) \n",
    "\n",
    "\n",
    "    H_sim_dir = os.path.join(BPTI_dir, \"alphafold_H\")\n",
    "\n",
    "    os.makedirs(H_sim_dir, exist_ok=True)\n",
    "\n",
    "    for pdb in pdb_list:\n",
    "        fixer = PDBFixer(os.path.join(sim_dir, pdb))\n",
    "        fixer.addMissingHydrogens(7.0)\n",
    "        H_pdb_name = pdb.replace('.pdb', '_H.pdb')\n",
    "        PDBFile.writeFile(fixer.topology, fixer.positions, open(os.path.join(H_sim_dir, H_pdb_name), 'w'), keepIds=True)\n",
    "\n",
    "    pdb_list = [f for f in os.listdir(H_sim_dir) if f.endswith('.pdb')]\n",
    "\n",
    "\n",
    "    top_path = os.path.join(H_sim_dir, pdb_list[0])\n",
    "    pdb_paths = [os.path.join(H_sim_dir, i) for i in pdb_list]\n",
    "\n",
    "    print(top_path)\n",
    "    print(pdb_paths)\n",
    "\n",
    "\n",
    "    small_traj_name = top_path.replace(\".pdb\",\"_small.xtc\")\n",
    "    small_traj_path = os.path.join(sim_dir, small_traj_name)\n",
    "\n",
    "    u = mda.Universe(top_path, pdb_paths)\n",
    "\n",
    "\n",
    "        \n",
    "    with XTCWriter(small_traj_path, n_atoms=u.atoms.n_atoms) as W:\n",
    "        for ts in u.trajectory:\n",
    "                W.write(u.atoms)\n",
    "\n",
    "    # traj_paths = [os.path.join(sim_dir, i) for i in os.listdir(sim_dir) if i.endswith(\".pdb\")]\n",
    "    \n",
    "    traj_paths = [small_traj_path]\n",
    "\n",
    "    print(traj_paths)\n",
    "    return hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name\n",
    "hdx_path, segs_path, rates_path, top_path, traj_paths, sim_name, expt_name, test_name = pre_process_main_LXRa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split_test_LXRa(split_mode, name, system):\n",
    "\n",
    "    # settings.split_mode = 'R'\n",
    "    settings.split_mode = split_mode\n",
    "    settings.name = \"_\".join([name, split_mode, system])\n",
    "    settings.times = [0.5,10.0]\n",
    "\n",
    "    VDX = ValDXer(settings)\n",
    "\n",
    "    VDX.load_HDX_data(HDX_path=hdx_path, SEG_path=segs_path, calc_name=expt_name)\n",
    "    # VDX.load_intrinsic_rates(path=rates_path, calc_name=expt_name)\n",
    "\n",
    "    VDX.load_structures(top_path=top_path, traj_paths=traj_paths, calc_name=test_name)\n",
    "\n",
    "    run_outputs = VDX.run_VDX(calc_name=test_name, expt_name=expt_name)\n",
    "    analysis_dump, df, name = VDX.dump_analysis()\n",
    "    save_path = VDX.save_experiment()\n",
    "\n",
    "    return run_outputs, analysis_dump, df, name, save_path\n",
    "\n",
    "\n",
    "splits = ['r', 's', 'R3',  'Sp', 'SR']\n",
    "split_names = ['naiverandom', 'NC_Termini', 'RedundantK',  'pINspace', 'spaceK']\n",
    "system = test_name\n",
    "\n",
    "# raw_run_outputs = {}\n",
    "# analysis_dumps = {}\n",
    "# analysis_df = pd.DataFrame()\n",
    "# names = []\n",
    "# save_paths = []\n",
    "\n",
    "\n",
    "for split, split_name in zip(splits, split_names):\n",
    "    run_outputs, analysis_dump, df, name, save_path = run_split_test_LXRa(split, split_name, system)\n",
    "    raw_run_outputs[name] = run_outputs\n",
    "    analysis_dumps.update(analysis_dump)\n",
    "    analysis_df = pd.concat([analysis_df, df])\n",
    "    names.append(name)\n",
    "    save_paths.append(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'your_dataframe' with your actual DataFrame variable\n",
    "df = analysis_df\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Create a FacetGrid, using 'name' for each subplot\n",
    "g = sns.FacetGrid(df, col=\"name\", col_wrap=5, height=4, aspect=1.5)\n",
    "g.fig.suptitle('MSE over Time by Type for each Named Split Mode')\n",
    "\n",
    "# Create boxplots\n",
    "g = g.map(sns.boxplot, \"time\", \"mse\", \"Type\", palette=\"Set3\")\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "g.add_legend(title='Type')\n",
    "g.set_axis_labels(\"Time\", \"MSE\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add slpit type to df\n",
    "\n",
    "df['split_type'] = df['name'].apply(lambda x: x.split('_')[0])\n",
    "df['dataset'] = df['calc_name'].apply(lambda x: x.split('_')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid, using 'split type' for each subplot\n",
    "df[\"protein\"] = df[\"calc_name\"].apply(lambda x: x.split(\"_\")[2] if len(x.split(\"_\")) > 2 else x.split(\"_\")[0])\n",
    "df[\"class\"] = df[\"dataset\"] + \"_\" + df[\"split_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'your_dataframe' with your actual DataFrame variable\n",
    "df = analysis_df\n",
    "\n",
    "# Create a FacetGrid, using 'name' for each subplot\n",
    "g = sns.FacetGrid(df, col=\"protein\", col_wrap=3, height=4, aspect=1.5)\n",
    "g.fig.suptitle('MSE over Time by Type for each protein and Split Mode')\n",
    "\n",
    "# Create boxplots\n",
    "g = g.map(sns.boxplot, \"time\", \"mse\", \"split_type\", palette=\"Set3\")\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "g.add_legend(title='Type')\n",
    "g.set_axis_labels(\"Time\", \"MSE\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'your_dataframe' with your actual DataFrame variable\n",
    "df = analysis_df\n",
    "\n",
    "# Create a FacetGrid, using 'name' for each subplot\n",
    "g = sns.FacetGrid(df, col=\"protein\", col_wrap=3, height=4, aspect=1.5)\n",
    "g.fig.suptitle('MSE over Time by Type for each prootein and Split Mode')\n",
    "\n",
    "# Create boxplots\n",
    "g = g.map(sns.boxplot, \"time\", \"mse\", \"class\", palette=\"Set3\")\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "g.add_legend(title='Type')\n",
    "g.set_axis_labels(\"Time\", \"MSE\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc, bh = 0.35, 2.0\n",
    "# Assuming your DataFrame is named BV_constants\n",
    "# Replace 'BV_constants' with your actual DataFrame variable\n",
    "plt.figure(figsize=(10, 6))  # Adjust the size of the figure here\n",
    "\n",
    "sns.boxplot(data=analysis_df, x=\"dataset\", y=\"mse\", hue=\"split_type\", palette=\"Set2\")\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "plt.xlabel(\"dataset\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE by class\")\n",
    "plt.legend(title=\"class\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc, bh = 0.35, 2.0\n",
    "# Assuming your DataFrame is named BV_constants\n",
    "# Replace 'BV_constants' with your actual DataFrame variable\n",
    "plt.figure(figsize=(20, 12))  # Adjust the size of the figure here\n",
    "\n",
    "sns.boxplot(data=analysis_df, x=\"time\", y=\"mse\", hue=\"class\", palette=\"Set2\")\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE by class\")\n",
    "plt.legend(title=\"name_name\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Replace 'your_dataframe' with your actual DataFrame variable\n",
    "df = analysis_df\n",
    "\n",
    "# Create a FacetGrid, using 'name' for each subplot\n",
    "g = sns.FacetGrid(df, col=\"name\", col_wrap=3, height=4, aspect=1.5)\n",
    "g.fig.suptitle('R over Time by Type for each Named Split Mode')\n",
    "\n",
    "# Create boxplots\n",
    "g = g.map(sns.boxplot, \"time\", \"R\", \"Type\", palette=\"Set3\")\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "g.add_legend(title='Type')\n",
    "g.set_axis_labels(\"Time\", \"R\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot LogPfs by Residues colour by calc_name facet wrap by name\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "LogPfs = pd.concat([analysis_dumps[i][\"LogPfs\"] for i in names])\n",
    "\n",
    "print(LogPfs)\n",
    "\n",
    "LogPfs_df = LogPfs.explode(['LogPf','Residues'])\n",
    "\n",
    "\n",
    "# Create a FacetGrid, using 'name' for each subplot\n",
    "g = sns.FacetGrid(LogPfs_df, col=\"name\", col_wrap=3, height=4, aspect=1.5)\n",
    "g.fig.suptitle('LogPfs over Residues for each Named Split Mode')\n",
    "\n",
    "# Create lineplots\n",
    "g = g.map(sns.lineplot, \"Residues\", \"LogPf\", \"calc_name\", palette=\"Set2\")\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "g.add_legend(title='calc_name')\n",
    "g.set_axis_labels(\"Residues\", \"LogPf\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot BV distributions \n",
    "# print(analysis_dumps[\"AvsB_S\"][\"BV_constants\"])\n",
    "\n",
    "BV_constants = pd.concat([analysis_dumps[i][\"BV_constants\"] for i in names])\n",
    "num_names = len(BV_constants)/len(names)\n",
    "BV_constants[\"name\"] = [i for i in names for j in range(int(num_names))]\n",
    "print(BV_constants)\n",
    "\n",
    "# Create a FacetGrid, using 'name' for each subplot - plot as scatter plot\n",
    "g = sns.FacetGrid(BV_constants, col=\"name\", col_wrap=3, height=4, aspect=1.5)\n",
    "g.fig.suptitle('BV Constants over Residues for each Named Split Mode')\n",
    "\n",
    "# Create lineplots\n",
    "g = g.map(sns.scatterplot, \"Bc\", \"Bh\", \"calc_name\", palette=\"Set2\")\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "g.add_legend(title='calc_name')\n",
    "g.set_axis_labels(\"Residues\", \"BV\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot BV distributions \n",
    "bc, bh = 0.35, 2\n",
    "\n",
    "BV_constants = pd.concat([analysis_dumps[i][\"BV_constants\"] for i in names])\n",
    "num_names = len(BV_constants)/len(names)\n",
    "BV_constants[\"name\"] = [i for i in names for j in range(int(num_names))]\n",
    "print(BV_constants)\n",
    "\n",
    "# Create a FacetGrid with a single axis\n",
    "g = sns.FacetGrid(BV_constants, height=4, aspect=1.5)\n",
    "g.fig.suptitle('BV Constants over Residues for each Named Split Mode')\n",
    "\n",
    "# Create scatter plot\n",
    "g = g.map(sns.scatterplot, \"Bc\", \"Bh\", \"name\", palette=\"Set2\", alpha=0.5)\n",
    "\n",
    "# Adding dashed lines at bc and bh\n",
    "plt.axhline(bh, color='grey', linestyle='dashed')\n",
    "plt.axvline(bc, color='grey', linestyle='dashed')\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "g.add_legend(title='name')\n",
    "g.set_axis_labels(\"Bc\", \"Bh\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights = pd.concat([analysis_dumps[i][\"weights\"] for i in names])\n",
    "num_names = len(weights)/len(names)\n",
    "weights[\"name\"] = [i for i in names for j in range(int(num_names))]\n",
    "print(weights)\n",
    "\n",
    "# explode weights - add index to get frames\n",
    "weights = weights.explode('weights').reset_index()\n",
    "# give each frame a number for each combination of name and calc_name   \n",
    "weights['frame'] = weights.groupby(['name', 'calc_name']).cumcount()\n",
    "\n",
    "\n",
    "print(weights)\n",
    "\n",
    "# plot weights on individual facets of each name\n",
    "# Create a FacetGrid, using 'name' for each subplot\n",
    "g = sns.FacetGrid(weights, col=\"name\", col_wrap=3, height=4, aspect=1.5)\n",
    "g.fig.suptitle('Weights over Residues for each Named Split Mode')\n",
    "\n",
    "# Create lineplots\n",
    "g = g.map(sns.lineplot, \"frame\", \"weights\", \"calc_name\", palette=\"Set2\")\n",
    "\n",
    "\n",
    "# Adding some additional options for better visualization\n",
    "g.add_legend(title='calc_name')\n",
    "g.set_axis_labels(\"Frame\", \"weight\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDXER_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
